# 编程评估功能使用说明

## 概述

本系统新增了专门针对编程类型问题的评估功能，支持三种数据集组织方式：
1. **有标准答案的编程题**：通过对比标准答案进行评估
2. **无标准答案的编程题**：通过评估模型判断代码质量
3. **混合数据集**：在同一个数据集中包含有标准答案和无标准答案的问题，支持一次性测试多种问题类型

## 目录结构

新的评估提示按数据集类型进行组织：

```
data/
├── evaluation_prompts/
│   ├── programming_mixed/                # 混合数据集评估提示
│   │   ├── prompt_mapping.json          # 提示文件映射配置
│   │   ├── binary_search_implementation.txt
│   │   └── student_grade_management_system.txt
│   └── programming_standard/             # 有标准答案编程题评估提示(未来扩展)
├── questions/
│   ├── programming_questions.json       # 原始编程问题集
│   ├── programming_questions_mixed.json # 混合数据集(推荐使用)
│   └── sample_questions.json           # 示例问题集
└── answers/
    ├── programming_answers.json         # 原始答案集
    ├── programming_answers_mixed.json   # 混合数据集答案(仅包含有标准答案的问题)
    └── sample_answers.json             # 示例答案集
```

### 评估提示映射机制

系统通过以下方式查找评估提示文件：

1. **问题ID精确匹配**：优先根据问题ID查找对应的提示文件
2. **关键词匹配**：如果ID匹配失败，则根据问题内容中的关键词进行匹配
3. **默认回退**：如果都匹配失败，使用默认命名规则

映射配置文件示例(`prompt_mapping.json`)：
```json
{
    "dataset_name": "programming_no_standard",
    "description": "无标准答案的编程问题评估提示映射",
    "question_mappings": [
        {
            "question_id": 1,
            "question_keywords": ["二分查找", "binary search", "有序数组", "索引位置"],
            "prompt_file": "binary_search_implementation.txt",
            "description": "二分查找算法实现"
        }
    ]
}
```

**关键词匹配示例**：
- 问题："请实现一个二分查找算法，在有序数组中查找目标元素"
- 匹配关键词：["二分查找", "有序数组"]
- 匹配文件：`binary_search_implementation.txt`

## 数据集结构

### 混合数据集（推荐使用）

**文件位置**：`data/questions/programming_questions_mixed.json`

混合数据集可以在同一个文件中包含有标准答案和无标准答案的编程问题，支持一次性测试多种问题类型。

**数据结构示例**：
```json
[
    {
        "id": 1,
        "question": "文本处理任务...",
        "category": "编程",
        "difficulty": "中等",
        "type": "standard_answer",
        "sub_questions": [...],
        "evaluation_prompt": "..."
    },
    {
        "id": 2,
        "question": "二分查找算法实现...",
        "category": "编程", 
        "difficulty": "中等",
        "type": "no_standard_answer",
        "sub_questions": [...]
    }
]
```

**对应答案文件**：`data/answers/programming_answers_mixed.json`
```json
[
    {
        "question_id": 1,
        "standard_answer": "标准代码实现...",
        "type": "standard_answer"
    }
    // 注意：只包含有标准答案问题的答案
]
```

**使用优势**：
- 一次性测试多种问题类型
- 减少数据管理复杂度
- 更好地模拟真实评估场景
- 支持混合评估策略

## 评估流程

### 模型回答格式

待评估模型需要将代码放在 `<model_answer>` 标签中：

```
<thinking>
思考过程（可选）
</thinking>

<model_answer>
# 代码实现
def example_function():
    pass
</model_answer>
```

### 评估维度

所有编程题都会从以下三个维度进行评估：

1. **准确性**：代码逻辑是否正确，能否正确实现所需功能
2. **完整性**：是否包含了题目要求的所有功能
3. **清晰度**：代码结构是否清晰，命名是否规范

### 评分机制

#### 有标准答案的编程题

- **子问题评分**：每个子问题完成得1分，未完成得0分
- **总分计算**：根据子问题权重加权平均 × 100
- **示例**：3个子问题权重[0.3, 0.3, 0.4]，完成情况[1, 0, 1]，总分 = (1×0.3 + 0×0.3 + 1×0.4) × 100 = 70分

#### 无标准答案的编程题

- **需求完成判断**：由评估模型判断是否完成基本需求
- **总分计算**：
  - 如果完成需求：(准确性 + 完整性 + 清晰度) / 3
  - 如果未完成需求：0分

## 使用方法

### 1. 准备数据集

创建编程问题和答案文件，按照上述格式组织数据。

### 2. 配置评估提示（仅无标准答案题目）

为无标准答案的问题配置评估提示文件：

1. **按数据集创建目录**：
   ```
   data/evaluation_prompts/{数据集名称}/
   ```

2. **创建映射配置文件**：
   ```json
   // data/evaluation_prompts/programming_no_standard/prompt_mapping.json
   {
       "dataset_name": "programming_no_standard",
       "description": "数据集描述",
       "question_mappings": [
           {
               "question_id": 1,
               "question_keywords": ["关键词1", "关键词2"],
               "prompt_file": "具体的提示文件名.txt",
               "description": "提示文件描述"
           }
       ]
   }
   ```

3. **创建具体的评估提示文件**：
   ```
   data/evaluation_prompts/programming_no_standard/binary_search_implementation.txt
   data/evaluation_prompts/programming_no_standard/student_grade_management_system.txt
   ```

### 3. 启动评估

通过Web界面或API创建评估任务：

```python
# API调用示例

# 混合数据集（推荐使用）
{
    "target_model_name": "待评估模型名称",
    "evaluator_model_name": "评估模型名称", 
    "question_file": "programming_questions_mixed.json",
    "answer_file": "programming_answers_mixed.json"
}

# 原始数据集（兼容性支持）
{
    "target_model_name": "待评估模型名称",
    "evaluator_model_name": "评估模型名称", 
    "question_file": "programming_questions.json",
    "answer_file": "programming_answers.json"
}
```

### 4. 查看结果

评估结果会包含：
- 各维度分数（准确性、完整性、清晰度）
- 总分
- 是否完成需求
- 子问题得分（有标准答案题目）
- 详细反馈

## 示例

### 示例1：文本处理任务（有标准答案）

**问题**：提取文本中的单词、网址，计算特定词出现次数

**子任务**：
1. 提取所有单词并转换为小写（权重30%）
2. 提取所有网址（权重30%）
3. 计算单词出现次数和位置（权重40%）

**评估结果**：
- 完整实现：准确性95分，完整性100分，清晰度90分，总分100分
- 部分实现：准确性60分，完整性40分，清晰度70分，总分30分

### 示例2：二分查找实现（无标准答案）

**问题**：实现二分查找算法

**评估维度**：
- 函数定义正确性（权重20%）
- 二分查找核心逻辑（权重40%）
- 边界情况处理（权重20%）
- 代码质量（权重20%）

**评估结果**：由评估模型综合判断代码质量和功能完整性

### 示例3：混合数据集评估

**数据集构成**：
- 问题1：文本处理任务（有标准答案）
- 问题2：二分查找算法（无标准答案）  
- 问题3：快速排序算法（有标准答案）
- 问题4：学生成绩管理系统（无标准答案）

**评估策略**：
- 有标准答案问题：使用子问题权重计算总分
- 无标准答案问题：使用评估模型判断并计算总分
- 混合结果：提供完整的评估报告，包含不同评估方式的结果

**优势**：
- 全面评估模型在不同类型编程问题上的表现
- 减少数据集管理成本
- 更接近真实应用场景

## 注意事项

1. **权重设置**：确保每个问题的子问题权重总和为1.0
2. **模型回答格式**：待评估模型必须使用`<model_answer>`标签包围代码
3. **评估模型选择**：选择能力强的模型作为评估模型，以确保评估质量
4. **提示文件**：无标准答案题目必须有对应的评估提示文件
5. **测试验证**：新增题目后建议先运行测试脚本验证格式正确性

## 扩展指南

### 添加新的编程题

1. 在对应的问题文件中添加新题目
2. 如果是有标准答案题目，在答案文件中添加标准答案
3. 如果是无标准答案题目：
   - 创建对应的评估提示文件
   - 更新映射配置文件，添加问题ID和关键词映射
   - 确保关键词能够准确匹配问题内容
4. 运行测试脚本验证格式正确性

### 添加新的数据集类型

1. 在`data/evaluation_prompts/`下创建新的数据集目录
2. 创建对应的`prompt_mapping.json`配置文件
3. 在`utils/prompt_loader.py`的`_determine_dataset_type`方法中添加数据集类型判断逻辑
4. 创建具体的评估提示文件

### 自定义评估维度

可以通过修改评估提示来调整评估重点，例如：
- 增加性能评估
- 增加代码风格检查
- 增加安全性评估

### 支持更多编程语言

目前主要支持Python，可以通过修改评估提示来支持其他编程语言的评估。 